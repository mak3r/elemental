{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 Elemental is a software stack enabling a centralized, full cloud-native OS management with Kubernetes. Cluster Node OSes are built and maintained via container images through the Elemental Toolkit and installed on new hosts using the Elemental CLI . The Elemental Operator and the Rancher System Agent enable Rancher Manager to fully control Elemental clusters, from the installation and management of the OS on the Nodes to the provisioning of new K3s or RKE2 clusters in a centralized way. Ready to give it a try? Get an Elemental Cluster up and running following the Quickstart section. Want more details? Take a look at the Architecture section or reach out to the #elemental Slack channel.","title":"Overview"},{"location":"#overview","text":"Elemental is a software stack enabling a centralized, full cloud-native OS management with Kubernetes. Cluster Node OSes are built and maintained via container images through the Elemental Toolkit and installed on new hosts using the Elemental CLI . The Elemental Operator and the Rancher System Agent enable Rancher Manager to fully control Elemental clusters, from the installation and management of the OS on the Nodes to the provisioning of new K3s or RKE2 clusters in a centralized way. Ready to give it a try? Get an Elemental Cluster up and running following the Quickstart section. Want more details? Take a look at the Architecture section or reach out to the #elemental Slack channel.","title":"Overview"},{"location":"architecture/","text":"Architecture \u00b6 Elemental is a stack, a set of tools, to build an immutable Linux distribution. Its primary purpose is to run Rancher and its corresponding Kubernetes distributions RKE2 and k3s . It can be configured for any other workload, however the following documentation focuses on a Rancher use-case. Initial node configurations is done using a cloud-init style approach and all further maintenance is done using Kubernetes operators. Use Cases \u00b6 The OS built by Elemental is intended to be run as the operating system beneath a Rancher Multi-Cluster Management server or as a node in a Kubernetes cluster managed by Rancher. As such it also allows you to build stand alone Kubernetes clusters that run an embedded and smaller version of Rancher to manage the local cluster. A key attribute of Elemental is that it is managed by Rancher and thus Rancher will exist either locally in the cluster or centrally with Rancher Multi-Cluster Manager. OCI Image based \u00b6 Elemental is an image based distribution with an A/B style update mechanism. One first runs on a read-only image A and to do an upgrade pulls a new read only image B and then reboots the system to run on B. What is unique about Elemental is that the runtime images come from OCI Images. Not an OCI Image containing special artifacts, but an actual Docker runnable image that is built using standard Docker build processes. Elemental is built using normal docker build and if you wish to customize the OS image all you need to do is create a new Dockerfile . Elemental Operator \u00b6 Elemental includes no container runtime, Kubernetes distribution, or Rancher itself. All of these assets are dynamically pulled at runtime. All that is included in Elemental is Elemental Operator which is responsible for managing OS upgrades and managing a secure device inventory to assist with zero touch provisioning. Elemental Operator includes a Kubernetes operator installed in the management cluster and a client side installed in nodes, so they can self register into the management cluster. Once a node is registered the Elemental Operator will kick-start the OS installation and schedule the Kubernetes provisioning using the Rancher System Agent . Rancher System Agent is responsible for bootstrapping RKE2/k3s and Rancher from an OCI registry. This means an update of containerd, k3s, RKE2, or Rancher does not require an OS upgrade or node reboot. Cloud-init \u00b6 Elemental is initially configured using a simple version of cloud-init . It is not expected that one will need to do a lot of customization to Elemental as the core OS's sole purpose is to run Rancher and Kubernetes and not serve as a generic Linux distribution. Elemental Teal \u00b6 Elemental Teal is the OS, based on SUSE Linux Enterprise (SLE) Micro for Rancher, built using the Elemental stack. The only assumption from the Elemental stack is that the underlying distribution is based on Systemd. We choose SLE Micro for Rancher for obvious reasons, but beyond that Elemental provides a stable layer to build upon that is well tested and has paths to commercial support, if one chooses.","title":"Architecture"},{"location":"architecture/#architecture","text":"Elemental is a stack, a set of tools, to build an immutable Linux distribution. Its primary purpose is to run Rancher and its corresponding Kubernetes distributions RKE2 and k3s . It can be configured for any other workload, however the following documentation focuses on a Rancher use-case. Initial node configurations is done using a cloud-init style approach and all further maintenance is done using Kubernetes operators.","title":"Architecture"},{"location":"architecture/#use-cases","text":"The OS built by Elemental is intended to be run as the operating system beneath a Rancher Multi-Cluster Management server or as a node in a Kubernetes cluster managed by Rancher. As such it also allows you to build stand alone Kubernetes clusters that run an embedded and smaller version of Rancher to manage the local cluster. A key attribute of Elemental is that it is managed by Rancher and thus Rancher will exist either locally in the cluster or centrally with Rancher Multi-Cluster Manager.","title":"Use Cases"},{"location":"architecture/#oci-image-based","text":"Elemental is an image based distribution with an A/B style update mechanism. One first runs on a read-only image A and to do an upgrade pulls a new read only image B and then reboots the system to run on B. What is unique about Elemental is that the runtime images come from OCI Images. Not an OCI Image containing special artifacts, but an actual Docker runnable image that is built using standard Docker build processes. Elemental is built using normal docker build and if you wish to customize the OS image all you need to do is create a new Dockerfile .","title":"OCI Image based"},{"location":"architecture/#elemental-operator","text":"Elemental includes no container runtime, Kubernetes distribution, or Rancher itself. All of these assets are dynamically pulled at runtime. All that is included in Elemental is Elemental Operator which is responsible for managing OS upgrades and managing a secure device inventory to assist with zero touch provisioning. Elemental Operator includes a Kubernetes operator installed in the management cluster and a client side installed in nodes, so they can self register into the management cluster. Once a node is registered the Elemental Operator will kick-start the OS installation and schedule the Kubernetes provisioning using the Rancher System Agent . Rancher System Agent is responsible for bootstrapping RKE2/k3s and Rancher from an OCI registry. This means an update of containerd, k3s, RKE2, or Rancher does not require an OS upgrade or node reboot.","title":"Elemental Operator"},{"location":"architecture/#cloud-init","text":"Elemental is initially configured using a simple version of cloud-init . It is not expected that one will need to do a lot of customization to Elemental as the core OS's sole purpose is to run Rancher and Kubernetes and not serve as a generic Linux distribution.","title":"Cloud-init"},{"location":"architecture/#elemental-teal","text":"Elemental Teal is the OS, based on SUSE Linux Enterprise (SLE) Micro for Rancher, built using the Elemental stack. The only assumption from the Elemental stack is that the underlying distribution is based on Systemd. We choose SLE Micro for Rancher for obvious reasons, but beyond that Elemental provides a stable layer to build upon that is well tested and has paths to commercial support, if one chooses.","title":"Elemental Teal"},{"location":"cloud-config-reference/","text":"Cloud-config reference \u00b6 All custom configuration applied on top of a fresh deployment should come from the cloud-config section in a MachineRegistration . This will get run by elemental-cli run-stage during the boot stage, and it will be stored in the node under the /oem dir. Elemental uses yip to run these cloud-config files, so we support the yip subset cloud-config implementation . Below is an example of the supported configuration on a MachineRegistration resource. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : \"bar\" passwd : \"foo\" groups : \"users\" homedir : \"/home/foo\" shell : \"/bin/bash\" ssh_authorized_keys : - faaapploo # Assigns these keys to the first user in users or root if there # is none ssh_authorized_keys : - asdd # Run these commands once the system has fully booted runcmd : - foo # Write arbitrary files write_files : - encoding : b64 content : CiMgVGhpcyBmaWxlIGNvbnRyb2xzIHRoZSBzdGF0ZSBvZiBTRUxpbnV4 path : /foo/bar permissions : \"0644\" owner : \"bar\" elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\"","title":"Cloud-config reference"},{"location":"cloud-config-reference/#cloud-config-reference","text":"All custom configuration applied on top of a fresh deployment should come from the cloud-config section in a MachineRegistration . This will get run by elemental-cli run-stage during the boot stage, and it will be stored in the node under the /oem dir. Elemental uses yip to run these cloud-config files, so we support the yip subset cloud-config implementation . Below is an example of the supported configuration on a MachineRegistration resource. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : \"bar\" passwd : \"foo\" groups : \"users\" homedir : \"/home/foo\" shell : \"/bin/bash\" ssh_authorized_keys : - faaapploo # Assigns these keys to the first user in users or root if there # is none ssh_authorized_keys : - asdd # Run these commands once the system has fully booted runcmd : - foo # Write arbitrary files write_files : - encoding : b64 content : CiMgVGhpcyBmaWxlIGNvbnRyb2xzIHRoZSBzdGF0ZSBvZiBTRUxpbnV4 path : /foo/bar permissions : \"0644\" owner : \"bar\" elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\"","title":"Cloud-config reference"},{"location":"customizing/","text":"Custom Images \u00b6 Elemental image can easily be remastered using a docker build. For example, to add cowsay to Elemental you would use the following Dockerfile Docker image \u00b6 # The version of Elemental to modify FROM registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:VERSION # Your custom commands RUN zypper install -y cowsay # IMPORTANT: /etc/os-release is used for versioning/upgrade. The # values here should reflect the tag of the image currently being built ARG IMAGE_REPO = norepo ARG IMAGE_TAG = latest RUN echo \"IMAGE_REPO= ${ IMAGE_REPO } \" > /etc/os-release && \\ echo \"IMAGE_TAG= ${ IMAGE_TAG } \" >> /etc/os-release && \\ echo \"IMAGE= ${ IMAGE_REPO } : ${ IMAGE_TAG } \" >> /etc/os-release Where VERSION is the base version we want to customize. And then the following commands docker build --build-arg IMAGE_REPO = myrepo/custom-build \\ --build-arg IMAGE_TAG = v1.1.1 \\ -t myrepo/custom-build:v1.1.1 . docker push myrepo/custom-build:v1.1.1 Your new customized OS is available at in the docker image myrepo/custom-build:v1.1.1 and you can check out your new image using docker with docker run -it myrepo/custom-build:v1.1.1 bash Installation ISO \u00b6 To create an ISO that upon boot will automatically attempt to register run the elemental-iso-build script bash elemental-iso-build CONFIG_FILE Where CONFIG_FILE is the path to the configuration file including the registration data to register against the Rancher management cluster.","title":"Custom Images"},{"location":"customizing/#custom-images","text":"Elemental image can easily be remastered using a docker build. For example, to add cowsay to Elemental you would use the following Dockerfile","title":"Custom Images"},{"location":"customizing/#docker-image","text":"# The version of Elemental to modify FROM registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:VERSION # Your custom commands RUN zypper install -y cowsay # IMPORTANT: /etc/os-release is used for versioning/upgrade. The # values here should reflect the tag of the image currently being built ARG IMAGE_REPO = norepo ARG IMAGE_TAG = latest RUN echo \"IMAGE_REPO= ${ IMAGE_REPO } \" > /etc/os-release && \\ echo \"IMAGE_TAG= ${ IMAGE_TAG } \" >> /etc/os-release && \\ echo \"IMAGE= ${ IMAGE_REPO } : ${ IMAGE_TAG } \" >> /etc/os-release Where VERSION is the base version we want to customize. And then the following commands docker build --build-arg IMAGE_REPO = myrepo/custom-build \\ --build-arg IMAGE_TAG = v1.1.1 \\ -t myrepo/custom-build:v1.1.1 . docker push myrepo/custom-build:v1.1.1 Your new customized OS is available at in the docker image myrepo/custom-build:v1.1.1 and you can check out your new image using docker with docker run -it myrepo/custom-build:v1.1.1 bash","title":"Docker image"},{"location":"customizing/#installation-iso","text":"To create an ISO that upon boot will automatically attempt to register run the elemental-iso-build script bash elemental-iso-build CONFIG_FILE Where CONFIG_FILE is the path to the configuration file including the registration data to register against the Rancher management cluster.","title":"Installation ISO"},{"location":"elemental-plans/","text":"Introduction \u00b6 Elemental uses the Rancher System Agent , renamed to Elemental System Agent, to initially bootstrap the node with a simple plan. The plan will apply the following configurations: - Set some labels for the node - Set the proper hostname according to the MachineInventory value - Install the default Rancher System Agent from Rancher Server, and install the proper Kubernetes components The bootstrap service also accepts local plans stored under /var/lib/elemental/agent/plans . Any plan written in there will also be applied during the initial node start after the installation is completed. Tip The local plans run only during the initial Elemental bootstrap before Kubernetes is installed on the node. Types of Plans \u00b6 The type of plans that Elemental can use are: One time instructions: Only run once Periodic instructions: They run periodically Files: Creates files Probes: http probes Tip Both one time instructions and periodic instructions can run either a direct command or a docker image. Adding local plans on Elemental \u00b6 You can add local plans to Elemental as part of the MachineRegistration CRD, in the cloud-config section as follows: apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root write_files : - path : /var/lib/elemental/agent/plans/mycustomplan.plan permissions : \"0600\" content : | {\"instructions\": [ { \"name\":\"set hostname\", \"command\":\"hostnamectl\", \"args\": [\"set-hostname\", \"myHostname\"] }, { \"name\":\"stop sshd service\", \"command\":\"systemctl\", \"args\": [\"stop\", \"sshd\"] } ] } elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\" Plan examples \u00b6 The following plans are provided as a quick reference and are not guaranteed to work in your environment. To learn more about plans please check Rancher System Agent . Example 1: one time instructions { \"instructions\" : [ { \"name\" : \"set hostname\" , \"command\" : \"hostnamectl\" , \"args\" : [ \"set-hostname\" , \"myHostname\" ] }, { \"name\" : \"stop sshd service\" , \"command\" : \"systemctl\" , \"args\" : [ \"stop\" , \"sshd\" ] } ] } Example 2: periodic instructions { \"periodicInstructions\" : [ { \"name\" : \"set hostname\" , \"image\" : \"ghcr.io/rancher-sandbox/elemental-example-plan:main\" \"command\" : \"run.sh\" } ] } Example 3: files { \"files\" : [ { \"content\" : \"Welcome to the system\" , \"path\" : \"/etc/motd\" , \"permissions\" : \"0644\" } ] } Example 4: probes { \"probes\" : \"probe1\" : { \"name\" : \"Service Up\" , \"httpGet\" : { \"url\" : \"http://10.0.0.1/healthz\" , \"insecure\" : \"false\" , \"clientCert\" : \"....\" , \"clientKey\" : \"....\" , \"caCert\" : \".....\" } } }","title":"Elemental plans"},{"location":"elemental-plans/#introduction","text":"Elemental uses the Rancher System Agent , renamed to Elemental System Agent, to initially bootstrap the node with a simple plan. The plan will apply the following configurations: - Set some labels for the node - Set the proper hostname according to the MachineInventory value - Install the default Rancher System Agent from Rancher Server, and install the proper Kubernetes components The bootstrap service also accepts local plans stored under /var/lib/elemental/agent/plans . Any plan written in there will also be applied during the initial node start after the installation is completed. Tip The local plans run only during the initial Elemental bootstrap before Kubernetes is installed on the node.","title":"Introduction"},{"location":"elemental-plans/#types-of-plans","text":"The type of plans that Elemental can use are: One time instructions: Only run once Periodic instructions: They run periodically Files: Creates files Probes: http probes Tip Both one time instructions and periodic instructions can run either a direct command or a docker image.","title":"Types of Plans"},{"location":"elemental-plans/#adding-local-plans-on-elemental","text":"You can add local plans to Elemental as part of the MachineRegistration CRD, in the cloud-config section as follows: apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root write_files : - path : /var/lib/elemental/agent/plans/mycustomplan.plan permissions : \"0600\" content : | {\"instructions\": [ { \"name\":\"set hostname\", \"command\":\"hostnamectl\", \"args\": [\"set-hostname\", \"myHostname\"] }, { \"name\":\"stop sshd service\", \"command\":\"systemctl\", \"args\": [\"stop\", \"sshd\"] } ] } elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\"","title":"Adding local plans on Elemental"},{"location":"elemental-plans/#plan-examples","text":"The following plans are provided as a quick reference and are not guaranteed to work in your environment. To learn more about plans please check Rancher System Agent . Example 1: one time instructions { \"instructions\" : [ { \"name\" : \"set hostname\" , \"command\" : \"hostnamectl\" , \"args\" : [ \"set-hostname\" , \"myHostname\" ] }, { \"name\" : \"stop sshd service\" , \"command\" : \"systemctl\" , \"args\" : [ \"stop\" , \"sshd\" ] } ] } Example 2: periodic instructions { \"periodicInstructions\" : [ { \"name\" : \"set hostname\" , \"image\" : \"ghcr.io/rancher-sandbox/elemental-example-plan:main\" \"command\" : \"run.sh\" } ] } Example 3: files { \"files\" : [ { \"content\" : \"Welcome to the system\" , \"path\" : \"/etc/motd\" , \"permissions\" : \"0644\" } ] } Example 4: probes { \"probes\" : \"probe1\" : { \"name\" : \"Service Up\" , \"httpGet\" : { \"url\" : \"http://10.0.0.1/healthz\" , \"insecure\" : \"false\" , \"clientCert\" : \"....\" , \"clientKey\" : \"....\" , \"caCert\" : \".....\" } } }","title":"Plan examples"},{"location":"elementaloperatorchart-reference/","text":"Elemental Operator Helm Chart \u00b6 The Elemental Operator is responsible for managing the Elemental versions and maintaining a machine inventory to assist with edge or baremetal installations. The associated chart bootstraps an elemental-operator deployment on the Rancher Manager v2.6 cluster using the Helm package manager. Prerequisites \u00b6 Rancher Manager version v2.6 Helm client version v3.8.0+ Get Helm chart info \u00b6 helm pull oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator helm show all oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator Install Chart \u00b6 helm install --create-namespace -n cattle-elemental-system elemental-operator \\ oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator The command deploys elemental-operator on the Kubernetes cluster in the default configuration. See configuration below. See helm install for command documentation. Uninstall Chart \u00b6 helm uninstall -n cattle-elemental-system elemental-operator This removes all the Kubernetes components associated with the chart and deletes the release. See helm uninstall for command documentation. Upgrading Chart \u00b6 helm upgrade -n cattle-elemental-system \\ --install elemental-operator \\ oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator See helm upgrade for command documentation. Configuration \u00b6 See Customizing the Chart Before Installing . To see all configurable options with detailed comments, visit the chart's values , or run these configuration commands: helm show values oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator Values \u00b6 Key Type Default Description image.empty string rancher/pause:3.1 image.repository string quay.io/costoolkit/elemental-operator Source image for elemental-operator with repository name image.tag tag \"\" image.imagePullPolicy string IfNotPresent noProxy string `127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,.svc,.cluster.local\" Comma separated list of domains or ip addresses that will not use the proxy global.cattle.systemDefaultRegistry string \"\" Default container registry name sync_interval string \"60m\" Default sync interval for upgrade channel sync_namespaces list [] Namespace the operator will watch for, leave empty for all debug bool false Enable debug output for operator nodeSelector.kubernetes.io/os string linux tolerations object {} tolerations.key string cattle.io/os tolerations.operator string \"Equal\" tolerations.value string \"linux\" tolerations.effect string NoSchedule","title":"Elemental Operator Helm Chart"},{"location":"elementaloperatorchart-reference/#elemental-operator-helm-chart","text":"The Elemental Operator is responsible for managing the Elemental versions and maintaining a machine inventory to assist with edge or baremetal installations. The associated chart bootstraps an elemental-operator deployment on the Rancher Manager v2.6 cluster using the Helm package manager.","title":"Elemental Operator Helm Chart"},{"location":"elementaloperatorchart-reference/#prerequisites","text":"Rancher Manager version v2.6 Helm client version v3.8.0+","title":"Prerequisites"},{"location":"elementaloperatorchart-reference/#get-helm-chart-info","text":"helm pull oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator helm show all oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator","title":"Get Helm chart info"},{"location":"elementaloperatorchart-reference/#install-chart","text":"helm install --create-namespace -n cattle-elemental-system elemental-operator \\ oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator The command deploys elemental-operator on the Kubernetes cluster in the default configuration. See configuration below. See helm install for command documentation.","title":"Install Chart"},{"location":"elementaloperatorchart-reference/#uninstall-chart","text":"helm uninstall -n cattle-elemental-system elemental-operator This removes all the Kubernetes components associated with the chart and deletes the release. See helm uninstall for command documentation.","title":"Uninstall Chart"},{"location":"elementaloperatorchart-reference/#upgrading-chart","text":"helm upgrade -n cattle-elemental-system \\ --install elemental-operator \\ oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator See helm upgrade for command documentation.","title":"Upgrading Chart"},{"location":"elementaloperatorchart-reference/#configuration","text":"See Customizing the Chart Before Installing . To see all configurable options with detailed comments, visit the chart's values , or run these configuration commands: helm show values oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator","title":"Configuration"},{"location":"elementaloperatorchart-reference/#values","text":"Key Type Default Description image.empty string rancher/pause:3.1 image.repository string quay.io/costoolkit/elemental-operator Source image for elemental-operator with repository name image.tag tag \"\" image.imagePullPolicy string IfNotPresent noProxy string `127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,.svc,.cluster.local\" Comma separated list of domains or ip addresses that will not use the proxy global.cattle.systemDefaultRegistry string \"\" Default container registry name sync_interval string \"60m\" Default sync interval for upgrade channel sync_namespaces list [] Namespace the operator will watch for, leave empty for all debug bool false Enable debug output for operator nodeSelector.kubernetes.io/os string linux tolerations object {} tolerations.key string cattle.io/os tolerations.operator string \"Equal\" tolerations.value string \"linux\" tolerations.effect string NoSchedule","title":"Values"},{"location":"installation/","text":"Installation \u00b6 Overview \u00b6 Elemental stack provides OS management using OCI containers and Kubernetes. The Elemental stack installation encompasses the installation of the Elemental Operator into the management cluster and the creation and use of Elemental Teal installation media to provide the OS into the Cluster Nodes. See Architecture section to read about the interaction of the components. The installation configuration is mostly applied and set as part of the registration process. The registration process is done by the Elemental Operator client who is the responsible to register nodes in a Rancher management cluster and fetch the installation configuration. Elemental Operator Installation \u00b6 The Elemental Operator is responsible for managing the Elemental versions and maintaining a machine inventory to assist with edge or baremetal installations. Elemental Operator requires a cluster including the Rancher Manager and it can be installed with a helm chart. See Elemental Operator helm chart reference for install, uninstall, upgrade and configuration details. Prepare Kubernetes Resources \u00b6 Once the Elemental Operator is up and running within the management cluster a couple of kuberentes resources are required in order to prepare an Elemental based cluster deployment. MachineInventorySelectorTemplate : This resource identifies the criteria to match registered boxes (listed as part of the MachineInventory) against available Rancher 2.6 Clusters. As soon as there is a match the matching kubernetes cluster takes ownership of the registered box. MachineRegistration : This resource defines OS deployment details for any machine attempting to register. The machine registration is the entrance for Elemental nodes as it handles the authentication (based on TPM), the Elemental Teal deployment and the node inclusion into to the MachineInventory so it can be added to a cluster when there is a match based on a MachineInventorySelectorTemplate. The MachineRegistration object includes the machine registration URL that nodes use to register against it. A Rancher Cluster resource is also required to deploy Elemental, it can be manually created as exemplified in the Quick Start guide or created from the Rancher 2.6 UI. Prepare Installation Media \u00b6 The installation media is the media that will be used to kick start an Elemental Teal deployment. Currently the supported media is a live ISO. The live ISO must include the registration configuration yaml hence it must crafted once the MachineRegistration is created. The installation media is created by using the elemental-iso-build helper script (see quick start guide) or by using the elemental build-iso command line utility included as part of the Elemental Toolkit . Within MachineRegistration only a subset of OS installation parameters can be configured, all available parameters listed at MachineRegistration reference page. In order to configure the installation beyond the common options provided within the elemental.install section a /etc/elemental/config.yaml config file can be included into the squashed rootfs of the installation media. Note any configuration applied as part of elemental.install section of the MachineRegistration will be applied on top of the settings included in /etc/elemental/config.yaml . Most likely the cloud-init configuration is enough to configure and set the deployed node at boot, however if for some reason some sort of firstboot actions or scripts are required it is possible to also include Rancher System Agent plans into the installation media. Refer to the Elemental Plans section for details for some example plans. The plans could be included into the squashed rootfs at /var/lib/elemental/agent/plans folder and they would be seen by the system agent at firstboot. Start Installation Process \u00b6 The installation starts by booting the installation media on a node. Once the installation media has booted it will attempt to contact the management cluster and register to it by calling elemental-register command. As the registration yaml configuration is already included into the ISO elemental-register knows the registration URL and any other required data for the registration. On a succeeded registration the installation media will start the Elemental Teal installation into the host based on the configuration already included in the media and the MachineRegistration parameters. As soon as the installation is done the node is ready to reboot. The deployed Elemental Teal includes a system agent plan to kick start a regular rancher provisioning process to install the selected kubernetes version, once booted, after some minutes the node installation is finalized and the node is included into the cluster and visible through the Rancher UI. Deployed Elemental Teal Partition Table \u00b6 Once Elemental Teal is installed the OS partition table, according to default values, will look like Label Default Size Contains COS_BOOT 64 MiB UEFI Boot partition COS_STATE 15 GiB A/B bootable file system images constructed from OCI images COS_OEM 64 MiB OEM cloud-config files and other data COS_RECOVERY 8 GiB Recovery file system image if COS_STATE is destroyed COS_PERSISTENT Remaining space All contents of the persistent folders Note this is the basic structure of any OS built by the Elemental Toolkit Elemental Teal Immutable Root \u00b6 One of the characteristics of Elemental OSes is the setup of an immutable root filesystem where some ephemeral or persistent locations are applied on top of it. Elemental Teal default folders structre is listed in the matrix below. Path Read-Only Ephemeral Persistent / x /etc x /etc/cni x /etc/iscsi x /etc/rancher x /etc/ssh x /etc/systemd x /srv x /home x /opt x /root x /var x /usr/libexec x /var/lib/cni x /var/lib/kubelet x /var/lib/longhorn x /var/lib/rancher x /var/lib/elemetal x /var/lib/wicked x /var/lib/calico x /var/log x","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#overview","text":"Elemental stack provides OS management using OCI containers and Kubernetes. The Elemental stack installation encompasses the installation of the Elemental Operator into the management cluster and the creation and use of Elemental Teal installation media to provide the OS into the Cluster Nodes. See Architecture section to read about the interaction of the components. The installation configuration is mostly applied and set as part of the registration process. The registration process is done by the Elemental Operator client who is the responsible to register nodes in a Rancher management cluster and fetch the installation configuration.","title":"Overview"},{"location":"installation/#elemental-operator-installation","text":"The Elemental Operator is responsible for managing the Elemental versions and maintaining a machine inventory to assist with edge or baremetal installations. Elemental Operator requires a cluster including the Rancher Manager and it can be installed with a helm chart. See Elemental Operator helm chart reference for install, uninstall, upgrade and configuration details.","title":"Elemental Operator Installation"},{"location":"installation/#prepare-kubernetes-resources","text":"Once the Elemental Operator is up and running within the management cluster a couple of kuberentes resources are required in order to prepare an Elemental based cluster deployment. MachineInventorySelectorTemplate : This resource identifies the criteria to match registered boxes (listed as part of the MachineInventory) against available Rancher 2.6 Clusters. As soon as there is a match the matching kubernetes cluster takes ownership of the registered box. MachineRegistration : This resource defines OS deployment details for any machine attempting to register. The machine registration is the entrance for Elemental nodes as it handles the authentication (based on TPM), the Elemental Teal deployment and the node inclusion into to the MachineInventory so it can be added to a cluster when there is a match based on a MachineInventorySelectorTemplate. The MachineRegistration object includes the machine registration URL that nodes use to register against it. A Rancher Cluster resource is also required to deploy Elemental, it can be manually created as exemplified in the Quick Start guide or created from the Rancher 2.6 UI.","title":"Prepare Kubernetes Resources"},{"location":"installation/#prepare-installation-media","text":"The installation media is the media that will be used to kick start an Elemental Teal deployment. Currently the supported media is a live ISO. The live ISO must include the registration configuration yaml hence it must crafted once the MachineRegistration is created. The installation media is created by using the elemental-iso-build helper script (see quick start guide) or by using the elemental build-iso command line utility included as part of the Elemental Toolkit . Within MachineRegistration only a subset of OS installation parameters can be configured, all available parameters listed at MachineRegistration reference page. In order to configure the installation beyond the common options provided within the elemental.install section a /etc/elemental/config.yaml config file can be included into the squashed rootfs of the installation media. Note any configuration applied as part of elemental.install section of the MachineRegistration will be applied on top of the settings included in /etc/elemental/config.yaml . Most likely the cloud-init configuration is enough to configure and set the deployed node at boot, however if for some reason some sort of firstboot actions or scripts are required it is possible to also include Rancher System Agent plans into the installation media. Refer to the Elemental Plans section for details for some example plans. The plans could be included into the squashed rootfs at /var/lib/elemental/agent/plans folder and they would be seen by the system agent at firstboot.","title":"Prepare Installation Media"},{"location":"installation/#start-installation-process","text":"The installation starts by booting the installation media on a node. Once the installation media has booted it will attempt to contact the management cluster and register to it by calling elemental-register command. As the registration yaml configuration is already included into the ISO elemental-register knows the registration URL and any other required data for the registration. On a succeeded registration the installation media will start the Elemental Teal installation into the host based on the configuration already included in the media and the MachineRegistration parameters. As soon as the installation is done the node is ready to reboot. The deployed Elemental Teal includes a system agent plan to kick start a regular rancher provisioning process to install the selected kubernetes version, once booted, after some minutes the node installation is finalized and the node is included into the cluster and visible through the Rancher UI.","title":"Start Installation Process"},{"location":"installation/#deployed-elemental-teal-partition-table","text":"Once Elemental Teal is installed the OS partition table, according to default values, will look like Label Default Size Contains COS_BOOT 64 MiB UEFI Boot partition COS_STATE 15 GiB A/B bootable file system images constructed from OCI images COS_OEM 64 MiB OEM cloud-config files and other data COS_RECOVERY 8 GiB Recovery file system image if COS_STATE is destroyed COS_PERSISTENT Remaining space All contents of the persistent folders Note this is the basic structure of any OS built by the Elemental Toolkit","title":"Deployed Elemental Teal Partition Table"},{"location":"installation/#elemental-teal-immutable-root","text":"One of the characteristics of Elemental OSes is the setup of an immutable root filesystem where some ephemeral or persistent locations are applied on top of it. Elemental Teal default folders structre is listed in the matrix below. Path Read-Only Ephemeral Persistent / x /etc x /etc/cni x /etc/iscsi x /etc/rancher x /etc/ssh x /etc/systemd x /srv x /home x /opt x /root x /var x /usr/libexec x /var/lib/cni x /var/lib/kubelet x /var/lib/longhorn x /var/lib/rancher x /var/lib/elemetal x /var/lib/wicked x /var/lib/calico x /var/log x","title":"Elemental Teal Immutable Root"},{"location":"kubernetesversions/","text":"Kubernetes versions \u00b6 Valid versions \u00b6 The list of valid versions for the kubernetesVersion field can be determined from the Rancher metadata using the following commands. k3s: curl -sL https://raw.githubusercontent.com/rancher/kontainer-driver-metadata/release-v2.6/data/data.json | jq -r '.k3s.releases[].version' rke2: curl -sL https://raw.githubusercontent.com/rancher/kontainer-driver-metadata/release-v2.6/data/data.json | jq -r '.rke2.releases[].version'","title":"Kubernetes versions"},{"location":"kubernetesversions/#kubernetes-versions","text":"","title":"Kubernetes versions"},{"location":"kubernetesversions/#valid-versions","text":"The list of valid versions for the kubernetesVersion field can be determined from the Rancher metadata using the following commands. k3s: curl -sL https://raw.githubusercontent.com/rancher/kontainer-driver-metadata/release-v2.6/data/data.json | jq -r '.k3s.releases[].version' rke2: curl -sL https://raw.githubusercontent.com/rancher/kontainer-driver-metadata/release-v2.6/data/data.json | jq -r '.rke2.releases[].version'","title":"Valid versions"},{"location":"machineinventoryselectortemplate-reference/","text":"MachineInventorySelectorTemplate reference \u00b6 The MachineInventorySelectorTemplate is the resource responsible of defining the matching criteria to pair an inventoried machine with a Cluster resource. The relevent key is the selector which includes label selector expressions. MachineInventorySelectorTemplate apiVersion : elemental.cattle.io/v1beta1 kind : MachineInventorySelectorTemplate metadata : name : my-machine-selector namespace : fleet-default spec : template : spec : selector : ... template.spec.selector can include matchLabels and or matchExpressions keys. template.spec.selector.matchLabels \u00b6 It is a map of {key,value} pairs (map[string]string). When multiple labels provided all must match. Example ... spec : template : spec : selector : matchlabels : location : europe manufacturer : somevalue In a Cluster defined with the above selector will only attempt to provision nodes inventoriarized including these two labels. template.spec.selector.matchExpressions \u00b6 It is a list of label selectors, each label selectors can be defined as: Key Type Description key string This is the label key the selector applies on operator string Represents the relationship of the key to a set of values. Valid operators are 'In', 'NotIn', 'Exists' and 'DoesNotExist' values []string Values is an array of string values. If the operator is 'In' or 'NotIn', the values array must be non-empty. If the operator is 'Exists' or 'DoesNotExist', the values array must be empty Example ... spec : template : spec : selector : matchExpressions : - key : location operator : In values : [ 'europe' ] - key : manufacturer operator : Exists In a Cluster defined with the above selector will only attempt to provision nodes inventoriarized the location=europe label and including a manufacturer label defined with any value.","title":"MachineInventorySelectorTemplate reference"},{"location":"machineinventoryselectortemplate-reference/#machineinventoryselectortemplate-reference","text":"The MachineInventorySelectorTemplate is the resource responsible of defining the matching criteria to pair an inventoried machine with a Cluster resource. The relevent key is the selector which includes label selector expressions. MachineInventorySelectorTemplate apiVersion : elemental.cattle.io/v1beta1 kind : MachineInventorySelectorTemplate metadata : name : my-machine-selector namespace : fleet-default spec : template : spec : selector : ... template.spec.selector can include matchLabels and or matchExpressions keys.","title":"MachineInventorySelectorTemplate reference"},{"location":"machineinventoryselectortemplate-reference/#templatespecselectormatchlabels","text":"It is a map of {key,value} pairs (map[string]string). When multiple labels provided all must match. Example ... spec : template : spec : selector : matchlabels : location : europe manufacturer : somevalue In a Cluster defined with the above selector will only attempt to provision nodes inventoriarized including these two labels.","title":"template.spec.selector.matchLabels"},{"location":"machineinventoryselectortemplate-reference/#templatespecselectormatchexpressions","text":"It is a list of label selectors, each label selectors can be defined as: Key Type Description key string This is the label key the selector applies on operator string Represents the relationship of the key to a set of values. Valid operators are 'In', 'NotIn', 'Exists' and 'DoesNotExist' values []string Values is an array of string values. If the operator is 'In' or 'NotIn', the values array must be non-empty. If the operator is 'Exists' or 'DoesNotExist', the values array must be empty Example ... spec : template : spec : selector : matchExpressions : - key : location operator : In values : [ 'europe' ] - key : manufacturer operator : Exists In a Cluster defined with the above selector will only attempt to provision nodes inventoriarized the location=europe label and including a manufacturer label defined with any value.","title":"template.spec.selector.matchExpressions"},{"location":"machineregistration-reference/","text":"MachineRegistration reference \u00b6 The MachineRegistration resource is the responsible of defining a machine registration end point. Once created in generates a registration URL used by nodes to register so they are inventoried. There are several keys that can be configured under a MachineRegistration resource spec. MachineRegistration apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineName : name machineInventoryLabels : label : value machineInventoryAnnotations : annotation : value config : cloud-config : ... elemental : registration : ... install : ... config.cloud-config \u00b6 Contains the cloud-configuration to be injected in the node. See the Cloud Config Reference for full information. config.elemental.registration \u00b6 Contains the configuration used for the connection and the initial registration to the Elemental Operator. Supports the following values: Key Type Description url string URL to connect to the Elemental Operator ca-cert string CA to validate the certificate provided by the server at 'url' (required if the certificate is not signed by a public CA) emulate-tpm bool this will use software emulation of the TPM (required for hosts without TPM hardware) emulated-tpm-seed int64 fixed seed to use with 'emulate-tpm': use for debug purposes only no-smbios bool wheter SMBIOS data should be sent to the Elemental Operator (see the SMBIOS reference for more information) config.elemental.install \u00b6 Contains the installation configuration that would be applied via operator-register when booted from an ISO and passed to elemental-cli install Supports the following values: Key Type Description firmware string Firmware to install ('efi' or 'bios') (default \"efi\") device string Device to install the system to no-format bool Don\u2019t format disks. It is implied that COS_STATE, COS_RECOVERY, COS_PERSISTENT, COS_OEM partitions are already existing on the target disk config-urls list Cloud-init config files locations iso string Performs an installation from the ISO url instead of the running ISO system-uri string Sets the system image source and its type (e.g. 'docker:registry.org/image:tag') instead of using the running ISO debug bool Enable debug output tty string Add named tty to grub poweroff bool Shutdown the system after install reboot bool Reboot the system after install eject-cd bool Try to eject the cd on reboot Warning In case of using both iso and system-uri the iso value takes precedence The only required value for a successful installation is the device key as we need a target disk to install to. The rest of the parameters are all optional. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : elemental : install : device : /dev/sda debug : true reboot : true eject-cd : true system-uri : registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest machineName \u00b6 This refers to the name that will be set to the node and the kubernetes resources that require a hostname (rke2 deployed pods for example, they use the node hostname as part of the pod names) String type. Info When elemental:registration:no-smbios is set to false (default), machineName is interpolated with SMBIOS data which allows you to store hardware information. See our SMBIOS docs for more information. If no machineName is specified, a default one in the form m-$UUID will be set. The UUID will be retrieved from the SMBIOS data if available, otherwise a random UUID will be generated. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineName : hostname-test-4 machineInventoryLabels \u00b6 Labels that will be set to the MachineInventory that is created from this MachineRegistration Key: value type. These labels will be used to stablish a selection criteria in MachineInventorySelectorTemplate . Info When elemental:registration:no-smbios is set to false (default), Labels are interpolated with SMBIOS data. This allows to store hardware information in custom labels. See our SMBIOS docs for more information. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineInventoryLabels : my.prefix.io/location : europe my.prefix.io/cpus : 32 my.prefix.io/manufacturer : \"${System Information/Manufacturer}\" my.prefix.io/productName : \"${System Information/Product Name}\" my.prefix.io/serialNumber : \"${System Information/Serial Number}\" my.prefix.io/machineUUID : \"${System Information/UUID}\" machineInventoryAnnotations \u00b6 Annotations that will be set to the MachineInventory that is created from this MachineRegistration Key: value type Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineInventoryAnnotations : owner : bob version : 1.0.0","title":"MachineRegistration reference"},{"location":"machineregistration-reference/#machineregistration-reference","text":"The MachineRegistration resource is the responsible of defining a machine registration end point. Once created in generates a registration URL used by nodes to register so they are inventoried. There are several keys that can be configured under a MachineRegistration resource spec. MachineRegistration apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineName : name machineInventoryLabels : label : value machineInventoryAnnotations : annotation : value config : cloud-config : ... elemental : registration : ... install : ...","title":"MachineRegistration reference"},{"location":"machineregistration-reference/#configcloud-config","text":"Contains the cloud-configuration to be injected in the node. See the Cloud Config Reference for full information.","title":"config.cloud-config"},{"location":"machineregistration-reference/#configelementalregistration","text":"Contains the configuration used for the connection and the initial registration to the Elemental Operator. Supports the following values: Key Type Description url string URL to connect to the Elemental Operator ca-cert string CA to validate the certificate provided by the server at 'url' (required if the certificate is not signed by a public CA) emulate-tpm bool this will use software emulation of the TPM (required for hosts without TPM hardware) emulated-tpm-seed int64 fixed seed to use with 'emulate-tpm': use for debug purposes only no-smbios bool wheter SMBIOS data should be sent to the Elemental Operator (see the SMBIOS reference for more information)","title":"config.elemental.registration"},{"location":"machineregistration-reference/#configelementalinstall","text":"Contains the installation configuration that would be applied via operator-register when booted from an ISO and passed to elemental-cli install Supports the following values: Key Type Description firmware string Firmware to install ('efi' or 'bios') (default \"efi\") device string Device to install the system to no-format bool Don\u2019t format disks. It is implied that COS_STATE, COS_RECOVERY, COS_PERSISTENT, COS_OEM partitions are already existing on the target disk config-urls list Cloud-init config files locations iso string Performs an installation from the ISO url instead of the running ISO system-uri string Sets the system image source and its type (e.g. 'docker:registry.org/image:tag') instead of using the running ISO debug bool Enable debug output tty string Add named tty to grub poweroff bool Shutdown the system after install reboot bool Reboot the system after install eject-cd bool Try to eject the cd on reboot Warning In case of using both iso and system-uri the iso value takes precedence The only required value for a successful installation is the device key as we need a target disk to install to. The rest of the parameters are all optional. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : elemental : install : device : /dev/sda debug : true reboot : true eject-cd : true system-uri : registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest","title":"config.elemental.install"},{"location":"machineregistration-reference/#machinename","text":"This refers to the name that will be set to the node and the kubernetes resources that require a hostname (rke2 deployed pods for example, they use the node hostname as part of the pod names) String type. Info When elemental:registration:no-smbios is set to false (default), machineName is interpolated with SMBIOS data which allows you to store hardware information. See our SMBIOS docs for more information. If no machineName is specified, a default one in the form m-$UUID will be set. The UUID will be retrieved from the SMBIOS data if available, otherwise a random UUID will be generated. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineName : hostname-test-4","title":"machineName"},{"location":"machineregistration-reference/#machineinventorylabels","text":"Labels that will be set to the MachineInventory that is created from this MachineRegistration Key: value type. These labels will be used to stablish a selection criteria in MachineInventorySelectorTemplate . Info When elemental:registration:no-smbios is set to false (default), Labels are interpolated with SMBIOS data. This allows to store hardware information in custom labels. See our SMBIOS docs for more information. Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineInventoryLabels : my.prefix.io/location : europe my.prefix.io/cpus : 32 my.prefix.io/manufacturer : \"${System Information/Manufacturer}\" my.prefix.io/productName : \"${System Information/Product Name}\" my.prefix.io/serialNumber : \"${System Information/Serial Number}\" my.prefix.io/machineUUID : \"${System Information/UUID}\"","title":"machineInventoryLabels"},{"location":"machineregistration-reference/#machineinventoryannotations","text":"Annotations that will be set to the MachineInventory that is created from this MachineRegistration Key: value type Example apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : machineInventoryAnnotations : owner : bob version : 1.0.0","title":"machineInventoryAnnotations"},{"location":"quickstart/","text":"Quickstart \u00b6 Follow this guide to have an auto-deployed cluster via rke2/k3s and managed by Rancher with the only help of an Elemental Teal iso Introduction \u00b6 What is Elemental Teal ? \u00b6 Elemental Teal is the combination of \"SLE Micro for Rancher\" with the Rancher Elemental stack SLE Micro for Rancher is a containerized and \"stripped to the bones\" operating system layer. It only requires grub2, dracut, a kernel, and systemd. Its sole purpose is to run Kubernetes (k3s or RKE2), with everything controlled through Rancher Manager. Elemental Teal is built in the openSUSE Build Service and available through the openSUSE Registry What is the Rancher Elemental Stack ? \u00b6 The Elemental Stack consists of some packages on top of SLE Micro for Rancher elemental-toolkit - includes a set of OS utilities to enable OS management via containers. Includes dracut modules, bootloader configuration, cloud-init style configuration services, etc. elemental-operator - this connects to Rancher Manager and handles machineRegistration and machineInventory CRDs elemental-register - this registers machines via machineRegistrations and installs them via elemental-cli elemental-cli - this installs any elemental-toolkit based derivative. Basically an installer based on our A/B install and upgrade system rancher-system-agent - runs on the installed system and gets instructions (\"Plans\") from Rancher Manager what to install and run on the system Prerequisites \u00b6 A Rancher server (2.6.6) configured (server-url set) To configure the Rancher server-url please check the Rancher docs A machine (bare metal or virtualized) with TPM 2.0 Hint 1: Libvirt allows setting virtual TPMs for virtual machines example here Hint 2: You can enable TPM emulation on bare metal machines missing the TPM 2.0 module example here Helm Package Manager (https://helm.sh/) Docker (for building the iso) Preparing the cluster \u00b6 elemental-operator is the management endpoint, running the management cluster and taking care of creating inventories, registrations for machines and much more. We will use the Helm package manager to install the elemental-operator chart into our cluster helm upgrade --create-namespace -n cattle-elemental-system --install elemental-operator oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator There is a few options that can be set in the chart install but that is out of scope for this document. You can see all the values on the chart values.yaml Now after a few seconds you should see the operator pod appear on the cattle-elemental-system namespace. kubectl get pods -n cattle-elemental-system NAME READY STATUS RESTARTS AGE elemental-operator-64f88fc695-b8qhn 1 /1 Running 0 16s Prepare you kubernetes resources \u00b6 Node deployment starts with a MachineRegistration , identifying a set of machines sharing the same configuration (disk drives, network, etc.) Then it continues with having a Cluster resource that uses a MachineInventorySelectorTemplate to know which machines are for that cluster. This selector is a simple matcher based on labels set in the MachineInventory , so if your selector is matching the cluster-id key with a value myId and your MachineInventory has that same key with that value, it will match and be bootstrapped as part of the cluster. Manually creating the resource yamls Using quickstart files from Elemental repo directly You will need to create the following files. selector.yaml apiVersion : elemental.cattle.io/v1beta1 kind : MachineInventorySelectorTemplate metadata : name : my-machine-selector namespace : fleet-default spec : template : spec : selector : matchExpressions : - key : location operator : In values : [ 'europe' ] As you can see this is a very simple selector named my-machine-selector that matches the key location for any values in the array with the one item: europe cluster.yaml kind : Cluster apiVersion : provisioning.cattle.io/v1 metadata : name : my-cluster namespace : fleet-default spec : rkeConfig : machinePools : - controlPlaneRole : true etcdRole : true machineConfigRef : apiVersion : elemental.cattle.io/v1beta1 kind : MachineInventorySelectorTemplate name : my-machine-selector name : pool1 quantity : 1 unhealthyNodeTimeout : 0s workerRole : true kubernetesVersion : v1.23.7+k3s1 As you can see we are setting our Cluster resource to a machineConfigRef which is of Kind MachineInventorySelectorTemplate with the name my-machine-selector , which matches the selector we created. registration.yaml apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\" manufacturer : \"${System Information/Manufacturer}\" productName : \"${System Information/Product Name}\" serialNumber : \"${System Information/Serial Number}\" machineUUID : \"${System Information/UUID}\" This creates a MachineRegistration resource which will provide a unique URL which we will use with elemental-register to register the node during installation, so the operator can create a MachineInventory which will be using to bootstrap the node. See that we set the label that match our selector here already, although it can always be added later to the MachineInventory . Warning Make sure to modify the registration.yaml above to set the proper install device to point to a valid device based on your node configuration(i.e. /dev/sda, /dev/vda, /dev/nvme0, etc...) Now that we have all the configuration to create the proper resources in Kubernetes just apply them kubectl apply -f selector.yaml kubectl apply -f cluster.yaml kubectl apply -f registration.yaml You can directly apply the quickstart example resource files from the Elemental repository Warning This assumes that your Node will have a /dev/sda disk available as that is the default device selected in those files. If your node doesnt have that device you will have to manually create the registration.yaml file or download the one from the repo and modify before applying kubectl apply -f https://raw.githubusercontent.com/rancher/elemental/main/examples/quickstart/selector.yaml kubectl apply -f https://raw.githubusercontent.com/rancher/elemental/main/examples/quickstart/cluster.yaml kubectl apply -f https://raw.githubusercontent.com/rancher/elemental/main/examples/quickstart/registration.yaml Preparing the iso \u00b6 Now this is the last step, we need to prepare an Elemental Teal iso that includes the initial registration config, so it can be auto registered, installed and fully deployed as part of our cluster. The contents of the file are nothing more than the registration url that the node needs to register and the proper server certificate, so it can connect securely. This iso then can be used to provision an infinite number of machines Now, our MachineRegistration provides the needed config in its resource as part of its Status.RegistrationURL , so we can use that url to obtain the proper yaml needed for the iso. One liner Full explanation wget --no-check-certificate ` kubectl get machineregistration -n fleet-default my-nodes -o jsonpath = \"{.status.registrationURL}\" ` -O initial-registration.yaml This will download the proper yaml from the registration URL and store it on the current directory under the initial-registration.yaml name First we need to obtain the RegistrationURL that was generated for our MachineRegistration kubectl get machineregistration -n fleet-default my-nodes -o jsonpath = \"{.status.registrationURL}\" Example output: https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp Then we need to visit that URL as that will provide the URL and CA certificate for unauthenticated requests: curl --insecure https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp Example output: elemental: registration: url: https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp ca-cert: |- -----BEGIN CERTIFICATE----- MIIBqDCCAU2gAwIBAgIBADAKBggqhkjOPQQDAjA7MRwwGgYDVQQKExNkeW5hbWlj bGlzdGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwHhcNMjIw ODA0MTA1OTE1WhcNMzIwODAxMTA1OTE1WjA7MRwwGgYDVQQKExNkeW5hbWljbGlz dGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwWTATBgcqhkjO PQIBBggqhkjOPQMBBwNCAASa8PJH7JJGT5QUPMBYnJe0j50G7dTEaDlk4xRpqVk1 y4dloslsI0RTb6B++7nNgnLPOe2KqZfylNmVIAelrSaUo0IwQDAOBgNVHQ8BAf8E BAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUxp8OBfjZlnyV6pzzKqIF wWByvCYwCgYIKoZIzj0EAwIDSQAwRgIhAPI2XUWcnxkkBe98SGPFa1Hlncyu/FCR AbEYIAdUC2z+AiEA+GizukSRiiLV28wdNdKihEELy+qzi5MlVYowUuQYZsA= -----END CERTIFICATE----- As you can see we obtained the proper initial registration needed by elemental-register to register the node properly and continue wiht the automated installation Now we can write down the data returned for that url into a file that we will inject into the iso initial-registration.yaml elemental : registration : url : https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp ca-cert : |- -----BEGIN CERTIFICATE----- MIIBqDCCAU2gAwIBAgIBADAKBggqhkjOPQQDAjA7MRwwGgYDVQQKExNkeW5hbWlj bGlzdGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwHhcNMjIw ODA0MTA1OTE1WhcNMzIwODAxMTA1OTE1WjA7MRwwGgYDVQQKExNkeW5hbWljbGlz dGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwWTATBgcqhkjO PQIBBggqhkjOPQMBBwNCAASa8PJH7JJGT5QUPMBYnJe0j50G7dTEaDlk4xRpqVk1 y4dloslsI0RTb6B++7nNgnLPOe2KqZfylNmVIAelrSaUo0IwQDAOBgNVHQ8BAf8E BAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUxp8OBfjZlnyV6pzzKqIF wWByvCYwCgYIKoZIzj0EAwIDSQAwRgIhAPI2XUWcnxkkBe98SGPFa1Hlncyu/FCR AbEYIAdUC2z+AiEA+GizukSRiiLV28wdNdKihEELy+qzi5MlVYowUuQYZsA= -----END CERTIFICATE----- Now we can proceed to create the ISO Via script We provide a ISO build script for ease of use that can create the final ISO and inject the initial-registration.yaml : wget -q https://raw.githubusercontent.com/rancher/elemental/main/elemental-iso-build && chmod +x elemental-iso-build Now that we have the script we can proceed to build the ISO with our configuration injected: ./elemental-iso-build initial-registration.yaml This will generate an ISO on the current directory with the name elemental-<timestamp>.iso You can now boot your nodes with this ISO, and they will: Boot from the ISO Register with the registrationURL given and create a per-machine MachineInventory Install Elemental Teal to the given device Restart Auto-deploy the cluster via k3s After a few minutes your new cluster will be fully provisioned!! How can I choose the kubernetes version and deployer for the cluster? \u00b6 On you cluster.yaml file there is a key in the Spec called kubernetesVersion . That sets the version and deployer that will be used for the cluster, for example for rke v1.23.6 while for rke2 would be v1.23.6+rke2r1 and for k3s v1.23.6+k3s1 To see all compatible versions check the Rancher Support Matrix PDF for rke/rke2/k3s versions and their components. You can also check our Version doc to know how to obtain those versions. How can I follow what is going on behind the scenes? \u00b6 You should be able to follow along what the machine is doing via: During ISO boot: ssh into the machine (user/pass: root/ros): running journalctl -f -t elemental will show you the output of the elemental-register and the elemental install Once the system is installed: On the Rancher UI -> Cluster Management you should see your new cluster and be able to see the Provisioning Log in the cluster details ssh into the machine (user/pass: Whatever your configured on the registration.yaml under Spec.config.cloud-config.users ): running journalctl -f -u elemental-system-agent will show the output of the initial elemental config and install of rancher-system-agent running journalctl -f -u rancher-system-agent will show the output of the boostrap of cluster components like k3s running journalctl -f -u k3s will show the logs of the k3s deployment","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"Follow this guide to have an auto-deployed cluster via rke2/k3s and managed by Rancher with the only help of an Elemental Teal iso","title":"Quickstart"},{"location":"quickstart/#introduction","text":"","title":"Introduction"},{"location":"quickstart/#what-is-elemental-teal","text":"Elemental Teal is the combination of \"SLE Micro for Rancher\" with the Rancher Elemental stack SLE Micro for Rancher is a containerized and \"stripped to the bones\" operating system layer. It only requires grub2, dracut, a kernel, and systemd. Its sole purpose is to run Kubernetes (k3s or RKE2), with everything controlled through Rancher Manager. Elemental Teal is built in the openSUSE Build Service and available through the openSUSE Registry","title":"What is Elemental Teal ?"},{"location":"quickstart/#what-is-the-rancher-elemental-stack","text":"The Elemental Stack consists of some packages on top of SLE Micro for Rancher elemental-toolkit - includes a set of OS utilities to enable OS management via containers. Includes dracut modules, bootloader configuration, cloud-init style configuration services, etc. elemental-operator - this connects to Rancher Manager and handles machineRegistration and machineInventory CRDs elemental-register - this registers machines via machineRegistrations and installs them via elemental-cli elemental-cli - this installs any elemental-toolkit based derivative. Basically an installer based on our A/B install and upgrade system rancher-system-agent - runs on the installed system and gets instructions (\"Plans\") from Rancher Manager what to install and run on the system","title":"What is the Rancher Elemental Stack ?"},{"location":"quickstart/#prerequisites","text":"A Rancher server (2.6.6) configured (server-url set) To configure the Rancher server-url please check the Rancher docs A machine (bare metal or virtualized) with TPM 2.0 Hint 1: Libvirt allows setting virtual TPMs for virtual machines example here Hint 2: You can enable TPM emulation on bare metal machines missing the TPM 2.0 module example here Helm Package Manager (https://helm.sh/) Docker (for building the iso)","title":"Prerequisites"},{"location":"quickstart/#preparing-the-cluster","text":"elemental-operator is the management endpoint, running the management cluster and taking care of creating inventories, registrations for machines and much more. We will use the Helm package manager to install the elemental-operator chart into our cluster helm upgrade --create-namespace -n cattle-elemental-system --install elemental-operator oci://registry.opensuse.org/isv/rancher/elemental/charts/elemental/elemental-operator There is a few options that can be set in the chart install but that is out of scope for this document. You can see all the values on the chart values.yaml Now after a few seconds you should see the operator pod appear on the cattle-elemental-system namespace. kubectl get pods -n cattle-elemental-system NAME READY STATUS RESTARTS AGE elemental-operator-64f88fc695-b8qhn 1 /1 Running 0 16s","title":"Preparing the cluster"},{"location":"quickstart/#prepare-you-kubernetes-resources","text":"Node deployment starts with a MachineRegistration , identifying a set of machines sharing the same configuration (disk drives, network, etc.) Then it continues with having a Cluster resource that uses a MachineInventorySelectorTemplate to know which machines are for that cluster. This selector is a simple matcher based on labels set in the MachineInventory , so if your selector is matching the cluster-id key with a value myId and your MachineInventory has that same key with that value, it will match and be bootstrapped as part of the cluster. Manually creating the resource yamls Using quickstart files from Elemental repo directly You will need to create the following files. selector.yaml apiVersion : elemental.cattle.io/v1beta1 kind : MachineInventorySelectorTemplate metadata : name : my-machine-selector namespace : fleet-default spec : template : spec : selector : matchExpressions : - key : location operator : In values : [ 'europe' ] As you can see this is a very simple selector named my-machine-selector that matches the key location for any values in the array with the one item: europe cluster.yaml kind : Cluster apiVersion : provisioning.cattle.io/v1 metadata : name : my-cluster namespace : fleet-default spec : rkeConfig : machinePools : - controlPlaneRole : true etcdRole : true machineConfigRef : apiVersion : elemental.cattle.io/v1beta1 kind : MachineInventorySelectorTemplate name : my-machine-selector name : pool1 quantity : 1 unhealthyNodeTimeout : 0s workerRole : true kubernetesVersion : v1.23.7+k3s1 As you can see we are setting our Cluster resource to a machineConfigRef which is of Kind MachineInventorySelectorTemplate with the name my-machine-selector , which matches the selector we created. registration.yaml apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\" manufacturer : \"${System Information/Manufacturer}\" productName : \"${System Information/Product Name}\" serialNumber : \"${System Information/Serial Number}\" machineUUID : \"${System Information/UUID}\" This creates a MachineRegistration resource which will provide a unique URL which we will use with elemental-register to register the node during installation, so the operator can create a MachineInventory which will be using to bootstrap the node. See that we set the label that match our selector here already, although it can always be added later to the MachineInventory . Warning Make sure to modify the registration.yaml above to set the proper install device to point to a valid device based on your node configuration(i.e. /dev/sda, /dev/vda, /dev/nvme0, etc...) Now that we have all the configuration to create the proper resources in Kubernetes just apply them kubectl apply -f selector.yaml kubectl apply -f cluster.yaml kubectl apply -f registration.yaml You can directly apply the quickstart example resource files from the Elemental repository Warning This assumes that your Node will have a /dev/sda disk available as that is the default device selected in those files. If your node doesnt have that device you will have to manually create the registration.yaml file or download the one from the repo and modify before applying kubectl apply -f https://raw.githubusercontent.com/rancher/elemental/main/examples/quickstart/selector.yaml kubectl apply -f https://raw.githubusercontent.com/rancher/elemental/main/examples/quickstart/cluster.yaml kubectl apply -f https://raw.githubusercontent.com/rancher/elemental/main/examples/quickstart/registration.yaml","title":"Prepare you kubernetes resources"},{"location":"quickstart/#preparing-the-iso","text":"Now this is the last step, we need to prepare an Elemental Teal iso that includes the initial registration config, so it can be auto registered, installed and fully deployed as part of our cluster. The contents of the file are nothing more than the registration url that the node needs to register and the proper server certificate, so it can connect securely. This iso then can be used to provision an infinite number of machines Now, our MachineRegistration provides the needed config in its resource as part of its Status.RegistrationURL , so we can use that url to obtain the proper yaml needed for the iso. One liner Full explanation wget --no-check-certificate ` kubectl get machineregistration -n fleet-default my-nodes -o jsonpath = \"{.status.registrationURL}\" ` -O initial-registration.yaml This will download the proper yaml from the registration URL and store it on the current directory under the initial-registration.yaml name First we need to obtain the RegistrationURL that was generated for our MachineRegistration kubectl get machineregistration -n fleet-default my-nodes -o jsonpath = \"{.status.registrationURL}\" Example output: https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp Then we need to visit that URL as that will provide the URL and CA certificate for unauthenticated requests: curl --insecure https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp Example output: elemental: registration: url: https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp ca-cert: |- -----BEGIN CERTIFICATE----- MIIBqDCCAU2gAwIBAgIBADAKBggqhkjOPQQDAjA7MRwwGgYDVQQKExNkeW5hbWlj bGlzdGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwHhcNMjIw ODA0MTA1OTE1WhcNMzIwODAxMTA1OTE1WjA7MRwwGgYDVQQKExNkeW5hbWljbGlz dGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwWTATBgcqhkjO PQIBBggqhkjOPQMBBwNCAASa8PJH7JJGT5QUPMBYnJe0j50G7dTEaDlk4xRpqVk1 y4dloslsI0RTb6B++7nNgnLPOe2KqZfylNmVIAelrSaUo0IwQDAOBgNVHQ8BAf8E BAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUxp8OBfjZlnyV6pzzKqIF wWByvCYwCgYIKoZIzj0EAwIDSQAwRgIhAPI2XUWcnxkkBe98SGPFa1Hlncyu/FCR AbEYIAdUC2z+AiEA+GizukSRiiLV28wdNdKihEELy+qzi5MlVYowUuQYZsA= -----END CERTIFICATE----- As you can see we obtained the proper initial registration needed by elemental-register to register the node properly and continue wiht the automated installation Now we can write down the data returned for that url into a file that we will inject into the iso initial-registration.yaml elemental : registration : url : https://172.18.0.2.sslip.io/elemental/registration/gsh4n8nj9gvbsjk4x7hxvnr5l6hmhbdbdffrmkwzrss2dtfbnpbmqp ca-cert : |- -----BEGIN CERTIFICATE----- MIIBqDCCAU2gAwIBAgIBADAKBggqhkjOPQQDAjA7MRwwGgYDVQQKExNkeW5hbWlj bGlzdGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwHhcNMjIw ODA0MTA1OTE1WhcNMzIwODAxMTA1OTE1WjA7MRwwGgYDVQQKExNkeW5hbWljbGlz dGVuZXItb3JnMRswGQYDVQQDExJkeW5hbWljbGlzdGVuZXItY2EwWTATBgcqhkjO PQIBBggqhkjOPQMBBwNCAASa8PJH7JJGT5QUPMBYnJe0j50G7dTEaDlk4xRpqVk1 y4dloslsI0RTb6B++7nNgnLPOe2KqZfylNmVIAelrSaUo0IwQDAOBgNVHQ8BAf8E BAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUxp8OBfjZlnyV6pzzKqIF wWByvCYwCgYIKoZIzj0EAwIDSQAwRgIhAPI2XUWcnxkkBe98SGPFa1Hlncyu/FCR AbEYIAdUC2z+AiEA+GizukSRiiLV28wdNdKihEELy+qzi5MlVYowUuQYZsA= -----END CERTIFICATE----- Now we can proceed to create the ISO Via script We provide a ISO build script for ease of use that can create the final ISO and inject the initial-registration.yaml : wget -q https://raw.githubusercontent.com/rancher/elemental/main/elemental-iso-build && chmod +x elemental-iso-build Now that we have the script we can proceed to build the ISO with our configuration injected: ./elemental-iso-build initial-registration.yaml This will generate an ISO on the current directory with the name elemental-<timestamp>.iso You can now boot your nodes with this ISO, and they will: Boot from the ISO Register with the registrationURL given and create a per-machine MachineInventory Install Elemental Teal to the given device Restart Auto-deploy the cluster via k3s After a few minutes your new cluster will be fully provisioned!!","title":"Preparing the iso"},{"location":"quickstart/#how-can-i-choose-the-kubernetes-version-and-deployer-for-the-cluster","text":"On you cluster.yaml file there is a key in the Spec called kubernetesVersion . That sets the version and deployer that will be used for the cluster, for example for rke v1.23.6 while for rke2 would be v1.23.6+rke2r1 and for k3s v1.23.6+k3s1 To see all compatible versions check the Rancher Support Matrix PDF for rke/rke2/k3s versions and their components. You can also check our Version doc to know how to obtain those versions.","title":"How can I choose the kubernetes version and deployer for the cluster?"},{"location":"quickstart/#how-can-i-follow-what-is-going-on-behind-the-scenes","text":"You should be able to follow along what the machine is doing via: During ISO boot: ssh into the machine (user/pass: root/ros): running journalctl -f -t elemental will show you the output of the elemental-register and the elemental install Once the system is installed: On the Rancher UI -> Cluster Management you should see your new cluster and be able to see the Provisioning Log in the cluster details ssh into the machine (user/pass: Whatever your configured on the registration.yaml under Spec.config.cloud-config.users ): running journalctl -f -u elemental-system-agent will show the output of the initial elemental config and install of rancher-system-agent running journalctl -f -u rancher-system-agent will show the output of the boostrap of cluster components like k3s running journalctl -f -u k3s will show the logs of the k3s deployment","title":"How can I follow what is going on behind the scenes?"},{"location":"smbios/","text":"Introduction \u00b6 The System Management BIOS (SMBIOS) specification defines data structures (and access methods) that can be used to read management information produced by the BIOS of a computer. This allows us to gather hardware information about the running system and use that as part of our labels. How does elemental uses SMBIOS data? \u00b6 The registration client tries to gather SMBIOS data by running dmidecode during the initial registration of the node and that data is sent to the registration controller to use on interpolating different fields in the inventory that we create for that node. Currently, we support interpolating that data into the machineName and the machineInventoryLabels of a machineRegistration The interpolation format is as follows: {$KEY/VALUE} and ${KEY/SUBKEY/VALUE} This can be mixed with normal strings so my-prefix-${KEY/VALUE} would result into the resolved values with my-prefix- prefixed For example, having the following SMBIOS data: System Information Manufacturer: My manufacturer Product Name: Awesome PC Version: Not Specified Serial Number: THX1138 Family: Toretto And setting the machineName to serial-${System Information/Serial Number} would result in the final value of serial-THX1138 This is useful to generate automatic names for machines based on their hardware values, for example using the UUID or the Product name. Our default machineName when the registration values are empty is \"m-${System Information/UUID}\" . Warning All non-valid characters will be changed into - automatically on parse. Valid characters for labels are alphanumeric and - , _ and . For machineName the constraints are stricter as that value is used for the hostname so valid values are lowercase alphanumeric and - only. A good use of SMBIOS data is to set up different labels for all your machines and get those values from the hardware directly. Having your machineInventoryLabels on the machineRegistration set to SMBIOS data would allow you to use selectors down the line to select similar machines. For example using the following label cpuFamily: \"${Processor Information/Family} would allow you to use a selector to search for i7 cpus in your machine fleet. registration example with smbios labels apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\" manufacturer : \"${System Information/Manufacturer}\" productName : \"${System Information/Product Name}\" serialNumber : \"${System Information/Serial Number}\" machineUUID : \"${System Information/UUID}\"","title":"Smbios"},{"location":"smbios/#introduction","text":"The System Management BIOS (SMBIOS) specification defines data structures (and access methods) that can be used to read management information produced by the BIOS of a computer. This allows us to gather hardware information about the running system and use that as part of our labels.","title":"Introduction"},{"location":"smbios/#how-does-elemental-uses-smbios-data","text":"The registration client tries to gather SMBIOS data by running dmidecode during the initial registration of the node and that data is sent to the registration controller to use on interpolating different fields in the inventory that we create for that node. Currently, we support interpolating that data into the machineName and the machineInventoryLabels of a machineRegistration The interpolation format is as follows: {$KEY/VALUE} and ${KEY/SUBKEY/VALUE} This can be mixed with normal strings so my-prefix-${KEY/VALUE} would result into the resolved values with my-prefix- prefixed For example, having the following SMBIOS data: System Information Manufacturer: My manufacturer Product Name: Awesome PC Version: Not Specified Serial Number: THX1138 Family: Toretto And setting the machineName to serial-${System Information/Serial Number} would result in the final value of serial-THX1138 This is useful to generate automatic names for machines based on their hardware values, for example using the UUID or the Product name. Our default machineName when the registration values are empty is \"m-${System Information/UUID}\" . Warning All non-valid characters will be changed into - automatically on parse. Valid characters for labels are alphanumeric and - , _ and . For machineName the constraints are stricter as that value is used for the hostname so valid values are lowercase alphanumeric and - only. A good use of SMBIOS data is to set up different labels for all your machines and get those values from the hardware directly. Having your machineInventoryLabels on the machineRegistration set to SMBIOS data would allow you to use selectors down the line to select similar machines. For example using the following label cpuFamily: \"${Processor Information/Family} would allow you to use a selector to search for i7 cpus in your machine fleet. registration example with smbios labels apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root elemental : install : reboot : true device : /dev/sda debug : true machineName : my-machine machineInventoryLabels : location : \"europe\" manufacturer : \"${System Information/Manufacturer}\" productName : \"${System Information/Product Name}\" serialNumber : \"${System Information/Serial Number}\" machineUUID : \"${System Information/UUID}\"","title":"How does elemental uses SMBIOS data?"},{"location":"tpm/","text":"Trusted Platform Module 2.0 (TPM) \u00b6 Trusted Platform Module (TPM, also known as ISO/IEC 11889) is an international standard for a secure cryptoprocessor, a dedicated microcontroller designed to secure hardware through integrated cryptographic keys. The term can also refer to a chip conforming to the standard. Add TPM module to virtual machine \u00b6 Easy way to add TPM to virtual machine is to use Libvirt with Virt-manager Create Virtual Machine \u00b6 After starting virt-manager create new virtual machine Vedify and edit hardware module list \u00b6 On the hardware configuration screen, verify list of modules and click Add Hardware button Add TPM module to VM \u00b6 From the list of emulated devices choose TPM module and add it to VM Finish VM configuration \u00b6 On the last screen verify once again if TPM module was added properly Add TPM emulation to bare metal machine \u00b6 During applying MachineRegistration add following key to the yaml config:elemental:registration:emulate-tpm: true registration-tpm.yaml apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root elemental : install : reboot : true device : /dev/sda debug : true registration : emulate-tpm : true machineName : my-machine machineInventoryLabels : location : \"europe\"","title":"Trusted Platform Module 2.0 (TPM)"},{"location":"tpm/#trusted-platform-module-20-tpm","text":"Trusted Platform Module (TPM, also known as ISO/IEC 11889) is an international standard for a secure cryptoprocessor, a dedicated microcontroller designed to secure hardware through integrated cryptographic keys. The term can also refer to a chip conforming to the standard.","title":"Trusted Platform Module 2.0 (TPM)"},{"location":"tpm/#add-tpm-module-to-virtual-machine","text":"Easy way to add TPM to virtual machine is to use Libvirt with Virt-manager","title":"Add TPM module to virtual machine"},{"location":"tpm/#create-virtual-machine","text":"After starting virt-manager create new virtual machine","title":"Create Virtual Machine"},{"location":"tpm/#vedify-and-edit-hardware-module-list","text":"On the hardware configuration screen, verify list of modules and click Add Hardware button","title":"Vedify and edit hardware module list"},{"location":"tpm/#add-tpm-module-to-vm","text":"From the list of emulated devices choose TPM module and add it to VM","title":"Add TPM module to VM"},{"location":"tpm/#finish-vm-configuration","text":"On the last screen verify once again if TPM module was added properly","title":"Finish VM configuration"},{"location":"tpm/#add-tpm-emulation-to-bare-metal-machine","text":"During applying MachineRegistration add following key to the yaml config:elemental:registration:emulate-tpm: true registration-tpm.yaml apiVersion : elemental.cattle.io/v1beta1 kind : MachineRegistration metadata : name : my-nodes namespace : fleet-default spec : config : cloud-config : users : - name : root passwd : root elemental : install : reboot : true device : /dev/sda debug : true registration : emulate-tpm : true machineName : my-machine machineInventoryLabels : location : \"europe\"","title":"Add TPM emulation to bare metal machine"},{"location":"upgrade/","text":"Upgrade \u00b6 All components in Elemental are managed using Kubernetes. Below is how to use Kubernetes approaches to upgrade the components. Elemental Teal node upgrade \u00b6 Elemental Teal is upgraded with the Elemental Operator. Refer to the Elemental Operator documentation for complete information. There are two ways of selecting nodes for upgrading. Via a cluster target, which will match ALL nodes in a cluster that matches our selector or via node selector, which will match nodes based on the node labels. Node selector allows us to be more targeted with the upgrade while cluster selector just selects all the nodes in a matched cluster. With clusterTarget With nodeSelector You can target nodes for an upgrade via a clusterTarget by setting it to the cluster name that you want to upgrade. All nodes in a cluster that matches that name will match and be upgraded. upgrade-cluster-target.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new Elemental version you would like to upgrade to or track the latest tag osImage : \"registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest\" clusterTargets : - clusterName : my-cluster You can target nodes for an upgrade via a nodeSelector by setting it to the label and value that you want to match. Any nodes containing that key with the value will match and be upgraded. upgrade-node-selector.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new Elemental version you would like to upgrade to osImage : \"registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest\" clusterTargets : - clusterName : my-cluster nodeSelector : matchLabels : location : \"europe\" Selecting source for upgrade \u00b6 Via osImage Via ManagedOSVersion Just specify an OCI image on the osImage field upgrade-cluster-target.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new Elemental version you would like to upgrade to or track the latest tag osImage : \"registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest\" clusterTargets : - clusterName : my-cluster In this case we use the auto populated ManagedOSVersion resources to set the wanted managedOSVersionName field. See section Managing available versions to understand how the ManagedOSVersion are managed. upgrade-managedos-version.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new ManagedOSVersion you would like to upgrade to managedOSVersionName : v0.1.0-alpha22-amd64 clusterTargets : - clusterName : my-cluster Warning If both osImage and ManagedOSVersion are defined in the same ManagedOSImage be aware that osImage takes precedence. Managing available versions \u00b6 An ManagedOSVersionChannel resource can be created in a Kubernetes cluster where the elemental operator is installed to synchronize available versions for upgrades. It has a syncer in order to generate ManagedOSVersion automatically. Currently, we provide a json syncer and a custom one. Json syncer Custom syncer This syncer will fetch a json from url and parse it into valid ManagedOSVersion resources. managed-os-version-channel-json.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSVersionChannel metadata : name : elemental-versions namespace : fleet-default spec : options : URI : \"https://raw.githubusercontent.com/rancher/elemental/main/examples/upgrade/versions.json\" Timeout : \"1m\" type : json A custom syncer allows more flexibility on how to gather ManagedOSVersion by allowing custom commands with custom images. This type of syncer allows to run a given command with arguments and env vars in a custom image and output a json file to /data/output /data/output is then automounted by the syncer and then parsed so it can gather create the proper versions. Info The only requirement to make your own custom syncer is to make it output a json file to /data/output and keep the correct json structure. See below for an example use of our discovery plugin , which gathers versions from either git or github releases. managed-os-version-channel-json.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSVersionChannel metadata : name : elemental-versions namespace : fleet-default spec : options : args : - github command : - /usr/bin/upgradechannel-discovery envs : - name : REPOSITORY value : rancher/elemental - name : IMAGE_PREFIX value : quay.io/costoolkit/elemental image : quay.io/costoolkit/upgradechannel-discovery:v0.3-4b83dbe type : custom In both cases the file that the operator expects to parse is a json file with the versions on it as follows versions.json [ { \"metadata\" : { \"name\" : \"v0.1.0\" }, \"spec\" : { \"version\" : \"v0.1.0\" , \"type\" : \"container\" , \"metadata\" : { \"upgradeImage\" : \"foo/bar:v0.1.0\" } } }, { \"metadata\" : { \"name\" : \"v0.2.0\" }, \"spec\" : { \"version\" : \"v0.2.0\" , \"type\" : \"container\" , \"metadata\" : { \"upgradeImage\" : \"foo/bar:v0.2.0\" } } } ]","title":"Upgrade"},{"location":"upgrade/#upgrade","text":"All components in Elemental are managed using Kubernetes. Below is how to use Kubernetes approaches to upgrade the components.","title":"Upgrade"},{"location":"upgrade/#elemental-teal-node-upgrade","text":"Elemental Teal is upgraded with the Elemental Operator. Refer to the Elemental Operator documentation for complete information. There are two ways of selecting nodes for upgrading. Via a cluster target, which will match ALL nodes in a cluster that matches our selector or via node selector, which will match nodes based on the node labels. Node selector allows us to be more targeted with the upgrade while cluster selector just selects all the nodes in a matched cluster. With clusterTarget With nodeSelector You can target nodes for an upgrade via a clusterTarget by setting it to the cluster name that you want to upgrade. All nodes in a cluster that matches that name will match and be upgraded. upgrade-cluster-target.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new Elemental version you would like to upgrade to or track the latest tag osImage : \"registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest\" clusterTargets : - clusterName : my-cluster You can target nodes for an upgrade via a nodeSelector by setting it to the label and value that you want to match. Any nodes containing that key with the value will match and be upgraded. upgrade-node-selector.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new Elemental version you would like to upgrade to osImage : \"registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest\" clusterTargets : - clusterName : my-cluster nodeSelector : matchLabels : location : \"europe\"","title":"Elemental Teal node upgrade"},{"location":"upgrade/#selecting-source-for-upgrade","text":"Via osImage Via ManagedOSVersion Just specify an OCI image on the osImage field upgrade-cluster-target.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new Elemental version you would like to upgrade to or track the latest tag osImage : \"registry.opensuse.org/isv/rancher/elemental/teal52/15.3/rancher/elemental-node-image/5.2:latest\" clusterTargets : - clusterName : my-cluster In this case we use the auto populated ManagedOSVersion resources to set the wanted managedOSVersionName field. See section Managing available versions to understand how the ManagedOSVersion are managed. upgrade-managedos-version.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSImage metadata : name : my-upgrade namespace : fleet-default spec : # Set to the new ManagedOSVersion you would like to upgrade to managedOSVersionName : v0.1.0-alpha22-amd64 clusterTargets : - clusterName : my-cluster Warning If both osImage and ManagedOSVersion are defined in the same ManagedOSImage be aware that osImage takes precedence.","title":"Selecting source for upgrade"},{"location":"upgrade/#managing-available-versions","text":"An ManagedOSVersionChannel resource can be created in a Kubernetes cluster where the elemental operator is installed to synchronize available versions for upgrades. It has a syncer in order to generate ManagedOSVersion automatically. Currently, we provide a json syncer and a custom one. Json syncer Custom syncer This syncer will fetch a json from url and parse it into valid ManagedOSVersion resources. managed-os-version-channel-json.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSVersionChannel metadata : name : elemental-versions namespace : fleet-default spec : options : URI : \"https://raw.githubusercontent.com/rancher/elemental/main/examples/upgrade/versions.json\" Timeout : \"1m\" type : json A custom syncer allows more flexibility on how to gather ManagedOSVersion by allowing custom commands with custom images. This type of syncer allows to run a given command with arguments and env vars in a custom image and output a json file to /data/output /data/output is then automounted by the syncer and then parsed so it can gather create the proper versions. Info The only requirement to make your own custom syncer is to make it output a json file to /data/output and keep the correct json structure. See below for an example use of our discovery plugin , which gathers versions from either git or github releases. managed-os-version-channel-json.yaml apiVersion : elemental.cattle.io/v1beta1 kind : ManagedOSVersionChannel metadata : name : elemental-versions namespace : fleet-default spec : options : args : - github command : - /usr/bin/upgradechannel-discovery envs : - name : REPOSITORY value : rancher/elemental - name : IMAGE_PREFIX value : quay.io/costoolkit/elemental image : quay.io/costoolkit/upgradechannel-discovery:v0.3-4b83dbe type : custom In both cases the file that the operator expects to parse is a json file with the versions on it as follows versions.json [ { \"metadata\" : { \"name\" : \"v0.1.0\" }, \"spec\" : { \"version\" : \"v0.1.0\" , \"type\" : \"container\" , \"metadata\" : { \"upgradeImage\" : \"foo/bar:v0.1.0\" } } }, { \"metadata\" : { \"name\" : \"v0.2.0\" }, \"spec\" : { \"version\" : \"v0.2.0\" , \"type\" : \"container\" , \"metadata\" : { \"upgradeImage\" : \"foo/bar:v0.2.0\" } } } ]","title":"Managing available versions"}]}